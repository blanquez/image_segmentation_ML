\documentclass{article}
\usepackage{indentfirst}

\title{AJUSTE DE PREDICTOR PARA IMAGE SEGMENTATION DATA SET}
\author{Antonio José Blánquez Pérez, Diego Navarro Cabrera}
\date{Proyecto final Aprendizaje Automático - Universidad de Granada}

\begin{document}
 \setlength{\parskip}{1em} 

	\maketitle
	
	% La organización en secciones es solo pa organizarme, luego se puede reestructurar todo

	\section{Definición del problema a resolver y enfoque elegido} % Blanquez
	%
	% Repasar traducciones de las clases, no estoy seguro de losa(brickface) ni de camino(path), que entiendo que es un camino de tierra.
	%
	La base de datos seleccionada es Image Segmentation Data Set, creada por el Vision Group perteneciente a la Universidad de Massachusetts. Está formada por varias fotografías recogidas de 7 bases de datos que contienen distintos elementos al aire libre, los cuales son losa, cielo, follaje, cemento, ventana, camino y césped. Cada imagen ha sido segmentada a mano de manera que cada instancia de nuestra base de datos es una región de 3x3 píxeles de alguna de ellas, teniendo cada una 19 atributos que se detallarán más adelante. 
	\par
	Con esta información se pretende generar un modelo mediante técnicas de aprendizaje supervisado que prediga correctamente, dada una sección de 3x3 píxeles de una imagen, a que clase de las 7 antes mencionadas pertenece.
	%
	% Se puede completar con algo más	
	
	\section{Argumentos a favor de la elección de los modelos} % Blanquez
	
	Se han elegido tres modelos candidatos para el problema que nos ocupa, uno lineal y dos no lineales. El modelo lineal ha sido seleccionado mediante validación cruzada entre dos posibilidades: Regresión Logística y Perceptrón, siendo esta última técnica la que mejor resultado proporciona y por tanto la seleccionada para comparar con los dos modelos no lineales. El modelo Perceptrón es un gran clasificador, sobre todo cuando los datos son linealmente separables, ya que si esto ocurre nos asegura una clasificación perfecta de los datos de la muestra de entrenamiento; siendo además, ayudado por el algoritmo Pocket, capaz de dar buenos resultados aún sin ser los datos linealmente separables.
	
	% Se puede completar más el lineal cuando confirmemos su uso
	
	% Faltan los modelos no lineales, aún no elegidos
	
	\section{Codificación de los datos de entrada para hacerlos útiles a los algoritmos} % Blanquez
	
	% Controlamos las primeras líneas de los archivos que no son datos?
	
	En principio los datos no necesitan ningún tipo de codificación para ser útiles en proceso de aprendizaje, no obstante se han convertido los datos a combinaciones cuadráticas de estos. Así damos potencia al ajuste ya que, aunque estén ajustados por un modelo lineal, los datos podrán estar clasificados como funciones cuadráticas. Para ello se ha hecho uso de la función $Polynomial\_Features$ del módulo $Preprocessing$ de Scikit-Learn, pasándole como parámetro el exponente 2 para obtener la susodicha combinación.
	
	%	Se ha hecho el siguiente cambio en los archivos originales
	%	.data -$>$ .tes
	%	.test -$>$ .tra
	%	ya que antes había 210 en tra y 2100 en test
	%
	%	En segmentation.names especifica que la distribución anterior es correcta, por qué?
	
	\section{Valoración del interés de la variables para el problema y selección de un subconjunto (en su caso)} % Diego
	
En cuanto a las variables medidas en cada instancia, todas parecen aportar información que uno podría considerar valiosa para identificar una imagen, y puesto que no es un número demasiado elevado de atributos no tenemos razones para intentar reducir la dimensionalidad del problema deshechando algunas de ellas o usando una técnica de reducción como PCA.
\par 
Si que hay una variable de la que nos vamos a deshacer, pero esto es debido a que funciona como una constante que toma el mismo valor en todas las instancias, esta variable es el número de píxeles por región, que es 9 en todos los casos. Al ser una variable que no cambia de una instancia a otra no nos aporta ninguna información que pueda ser útil para nuestro modelo, por lo que eliminarla no afecta a la solución, pero si al tiempo de ejecución, que se ve reducido al tener que tratar con menos datos.
	
	%	El resto parecen ser medidas sobre la geometría y el color de la imagen, y por lo tanto necesarias
	
	\section{Normalización de las variables(en su caso)} % Diego
	Puesto que el rango de los atributos varia de unos a otros es importante reescalar cada uno de forma independiente para poder compararlos mejor y no darle más o menos peso a cada atributo en función de su tamaño. Para esto usaremos una escala min-max que para cada atributo $x_i$ perteneciente a la muestra i calcula:
\begin{equation}
x_i' = \frac{x_i-min}{max-min}
\end{equation}
\indent Donde min y max son los valores mínimo y máximo del atributo en toda la muestra.
\par 
Este tipo de escala mantiene la distribución de los valores, pero los ajusta a un rango entre 0 y 1.  Si supiéramos que los datos se siguen un tipo de distribución como la distribución normal podríamos usar otras formas de normalización, pero este no parece ser el caso, por lo que usar estas otras técnicas modificaría la distribución de la muestra y provocaría un peor ajuste.
\par 
Para evitar mezclar la información del conjunto de entrenamiento con la del de prueba aplicaremos este ajuste en cada conjunto de forma independiente, ya que si no no podríamos confiar en el valor de $E_{test}$ para estimar $E_{out}$.
	
	
	\section{Justificación de la función de pérdida usada} % Blanquez
	
	
	
	\section{Selección de las técnica (paramétrica) y valoración de la idoneidad de la misma frente a otras alternativas} % Diego - Lineal - No lineal 1 / Blanquez - No lineal 2
	\subsection{Modelo Lineal}
	Para ajustar el modelo lineal vamos a usar la función de la biblioteca sklearn del gradiente descendente estocástico SGDClassifier. Vamos a comparar entre 2 modelos diferentes, y decidiremos cual es mejor en tiempo de ejecución. Los modelos que vamos a comparar son regresión logística y la implementación que usa la biblioteca del Perceptrón.
	\par 
	Usamos SGD como técnica	de ajuste porque es un algoritmo de optimización ámpliamente usado para ajustar todo tipo de modelos, y su implementación en scikit-learn nos facilitará su uso y el ajuste de todos sus posibles parámetros. 
	\subsection{Boosting}
	Como técnica de boosting vamos a usar gradient boosting, que aunque no use funciones stamp como se recomienda en el guión, funciona mucho mejor que AdaBoost u otras funciones que si las usen. Esto se debe a que puesto que nuestro conjunto de datos de entrenamiento es muy pequeño y simple, estimadores muy débiles no son lo suficientemente buenos como para contribuir de forma tan significativa como en casos más complejos, y sobre todo, un conjunto de entrenamiento pequeño requiere de un tiempo de aprendizaje mucho menor y por lo tanto es viable usar métodos más exigentes como gradient boosting, que requiere de significativamente más tiempo que AdaBoost para el ajuste. 
	\section{Aplicación de la técnica especificando claramente que algoritmos se usan en la estimación de los parámetros, los hiperparámetros y el error de generalización.} % Diego - Lineal - No lineal 1 / Blanquez - No lineal 2
	Para ajustar los hiperparámetros de todos los modelos usaremos la función GridSearchCV de la biblioteca scikit-learn, que recibe un conjunto de valores posibles para los distintos parámetros que se quieren ajustar y usa validación cruzada para determinar cual es la mejor combinación de dichos valores.
	\subsection{Modelo Lineal}
	Para el ajuste de los modelos lineales nos centraremos en 2 parámetros que ajustaremos con GridSearchCV: loss, que indicará el modelo ajustado, que podrá ser log (regresión logística) o perceptron, como ya se ha comentado antes; y el factor de regularización, que provocará una regularización más o menos agresiva en función de lo alto que sea.
	\par 
	A parte de estos parámetros, es importante determinar el tipo de regularización usada, que en este caso será la regularización Lasso, ya que no parece que los atributos estén muy correlados y algunas características podría interesarnos que algunas características influyesen más en el modelo que otras.
	\par 
	El resto de parámetros que usa la función pueden dejarse tal y como están puesto que sirven más para definir el comportamiento del algoritmo para alcanzar la solución lo más rápido posible o determinar cuando parar la búsqueda, pero los valores por defecto ya son bastante buenos y modificarlos no nos llevaría a mejores soluciones, si no quizás a reducir los tiempos de ejecución. 
	\subsection{Boosting}
	El principal parámetro que determinará la calidad de nuestro modelo es el número de estimadores, que indicará el número de etapas de la fase de aprendizaje. Puesto que este método es bastante resistente al sobreajuste, no hará falta hacer muchas pruebas para ajustar este valor, puesto que podemos elegir un número que consideremos lo suficientemente alto sin miedo a pasarnos y obtener un mal ajuste.
	\par 
	 El resto de parámetros podemos decir que al igual que con SGDClassifier, modificarlos no afectaría significativamente a la calidad del resultado, por lo que podemos dejarlos con sus valores por defecto.
	
	\section{Argumentar sobre la idoneidad de la función regularización usada (en su caso)} % Blanquez (Lasso cuando se pueda)
	
	
	
	\section{Valoración de los resultados ( gráficas, métricas de error, análisis de residuos, etc )} % Hacer juntos al final
	
	
	
	\section{Justificar que se ha obtenido la mejor de las posibles soluciones con la técnica elegida y la muestra dada. Argumentar en términos de los errores de ajuste y generalización} % Hacer juntos al final
	
	
	
\end{document}